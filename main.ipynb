{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ebd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 30, 800)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # input_question = \"I'm going to classify the following chinese medicine spectral data.\"\n",
    "# input_question = \"I'm going to anomaly detect the chinese medicine spectral data.\"\n",
    "# data = np.load(r'data\\CN_medicine\\cnml.npy')\n",
    "\n",
    "input_question = \"I'm going to classify the following Citri Reticulatae Pericarpium spectral data.\"\n",
    "# input_question = \"I'm going to anomaly detect the Citri Reticulatae Pericarpium spectral data.\"\n",
    "data = np.load(r'data\\Chenpi\\chenpi.npy')\n",
    "\n",
    "# input_question = \"I'm going to classify the following milk spectral data.\"\n",
    "# # input_question = \"I'm going to anomaly detect the following milk spectral data.\"\n",
    "# data = np.load(r'data\\milk\\milk_data.npy')\n",
    "\n",
    "# input_question = \"I'm going to predict the waste water spectral data quality of COD.\"\n",
    "# data = np.load(r'data\\H2O\\H2Odata_js.npy')\n",
    "# Y = np.load(r'data\\H2O\\H2Olabel_js.npy')\n",
    "\n",
    "\n",
    "# input_question = \"I'm going to predict the fat content in meat sample.\"\n",
    "# X = np.load(r'data\\tecator\\tecator_data.npy')\n",
    "# Y = np.load(r'data\\tecator\\tecator_label.npy')\n",
    "# data=X.reshape(1, X.shape[0], -1)\n",
    "# Y = Y.reshape(1, 215, 1)\n",
    "\n",
    "\n",
    "# input_question = \"I'm going to predict the protein content in corn samples.\"\n",
    "# data = np.load(r'data\\corn\\corn_data.npy')\n",
    "# Y = np.load(r'data\\corn\\protein_label.npy')\n",
    "# data=data.reshape(1, data.shape[0], -1)\n",
    "# Y = Y.reshape(1, Y.shape[1], 1)\n",
    "# regression_label = Y\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# retrieval API\n",
    "API = \"\"\n",
    "base_url = \"\"\n",
    "\n",
    "## model generation API\n",
    "model_API =  \"\"\n",
    "model_url = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a088187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research object: Citri Reticulatae Pericarpium\n",
      "Task type: classification\n"
     ]
    }
   ],
   "source": [
    "import Entity_extraction\n",
    "extracted = Entity_extraction.extract_entities_and_task(input_question, API, base_url, model_name=\"qwen-plus\")\n",
    "\n",
    "research_object = extracted['research_object']\n",
    "task_type       = extracted['task_type']\n",
    "\n",
    "print(\"Research object:\", research_object)\n",
    "print(\"Task type:\", task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878e17bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper_Name: On-site rapid detection of aging of Pericarpium Citri Reticulatae using multispectral imaging\n",
      "Relevant Scores: 17.40200851119497\n",
      "Paper_Name: Simultaneous determination of six bioactive flavonoids in Citri Reticulatae Pericarpium by rapid resolution liquid chromatography coupled with triple quadrupole electrospray tandem mass spectrometry\n",
      "Relevant Scores: 14.25829759091841\n",
      "Paper_Name: Hazelnut quality detection based on deep learning and near-infrared spectroscopy\n",
      "Relevant Scores: 0.0\n",
      "[{'paper_name': 'On-site rapid detection of aging of Pericarpium Citri Reticulatae using multispectral imaging', 'preprocessing_method': 'SNV', 'feature_extracting_method': 'PCA'}, {'paper_name': 'Simultaneous determination of six bioactive flavonoids in Citri Reticulatae Pericarpium by rapid resolution liquid chromatography coupled with triple quadrupole electrospray tandem mass spectrometry', 'preprocessing_method': 'Ultrasonation extraction with methanol for 30 min, filtration, and centrifugation at 14,000 g for 10 min', 'feature_extracting_method': 'RRLCâ€“ESI-MSn method'}, {'paper_name': 'Hazelnut quality detection based on deep learning and near-infrared spectroscopy', 'preprocessing_method': 'first derivative', 'feature_extracting_method': 'Resnet-50'}]\n"
     ]
    }
   ],
   "source": [
    "import Retrieval\n",
    "\n",
    "json_path = \"./structured_papers1.json\"\n",
    "\n",
    "papers_list = Retrieval.load_papers_from_json(json_path)\n",
    "\n",
    "bm25_index, tokenized_names = Retrieval.build_bm25_index(papers_list)\n",
    "top_k = 3\n",
    "\n",
    "matched_info = Retrieval.search_papers_with_bm25(\n",
    "    papers=papers_list,\n",
    "    bm25=bm25_index,\n",
    "    tokenized_paper_names=tokenized_names,\n",
    "    query=research_object,\n",
    "    top_k=top_k\n",
    ")\n",
    "\n",
    "print(matched_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba07732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'On-site rapid detection of aging of Pericarpium Citri Reticulatae using multispectral imaging': {'preprocessing': ['standard_normal_variate'], 'features': ['pca_feature_extraction']}, 'Simultaneous determination of six bioactive flavonoids in Citri Reticulatae Pericarpium by rapid resolution liquid chromatography coupled with triple quadrupole electrospray tandem mass spectrometry': {'preprocessing': [], 'features': []}, 'Hazelnut quality detection based on deep learning and near-infrared spectroscopy': {'preprocessing': ['spectral_derivative'], 'features': []}}\n",
      "Selected (majority + fallback): {'preprocessing': ['standard_normal_variate'], 'features': ['pca_feature_extraction']}\n",
      "(8, 30, 800)\n",
      "Feature 'pca_feature_extraction' shape: (8, 30, 5)\n"
     ]
    }
   ],
   "source": [
    "import Agent\n",
    "\n",
    "Default_mode = True\n",
    "\n",
    "if Default_mode:\n",
    "    agent = Agent.SpectralAgent(\n",
    "        api_key=API,\n",
    "        base_url=base_url,\n",
    "        model_name=\"qwen-plus\",\n",
    "        regression_label=Y if task_type == 'regression' else None,\n",
    "    )\n",
    "\n",
    "    methods_map = agent.decide_methods_per_paper(matched_info)\n",
    "    print(methods_map)\n",
    "\n",
    "    paper_order = [m['paper_name'] for m in matched_info] \n",
    "\n",
    "    # 1) Standard usage: majority voting among top K; if tied or zero votes, fall back to the first \"complete\" paper among top K\n",
    "    selected = agent.select_methods(\n",
    "        methods_map,\n",
    "        k=3,\n",
    "        paper_order=paper_order,\n",
    "        require_both=True,   # Require both \"preprocessing + features\"\n",
    "    )\n",
    "    print(\"Selected (majority + fallback):\", selected)\n",
    "\n",
    "\n",
    "else:\n",
    "# Free selection (by index)\n",
    "    selected_by_idx = agent.select_methods(\n",
    "        methods_map,\n",
    "        k=3,\n",
    "        paper_order=paper_order,\n",
    "        prefer_paper=2,       # Pass 2 to select the 2nd paper; pass 1 or 0 to indicate 1-based/0-based indexing for the 1st paper\n",
    "        prefer_strict=True,\n",
    "        require_both=True,\n",
    "    )\n",
    "    print(\"Selected (prefer by index):\", selected_by_idx)\n",
    "\n",
    "# Process data and extract features using selected methods\n",
    "processed_data, features = agent.process_with_methods(data, selected)\n",
    "print(processed_data.shape)\n",
    "for fn, arr in features.items():\n",
    "    print(f\"Feature '{fn}' shape:\", arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76758dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 144\n",
      "Validation samples: 48, labels: ['2', '8', '2', '1', '3', '6', '2', '5', '8', '4', '4', '5', '6', '3', '3', '5', '7', '4', '5', '8', '3', '2', '4', '5', '7', '8', '5', '6', '3', '8', '6', '3', '1', '7', '6', '4', '1', '1', '7', '6', '7', '2', '2', '4', '7', '1', '1', '8']\n",
      "Test samples: 48, labels: ['5', '5', '3', '2', '1', '1', '3', '5', '8', '1', '4', '1', '3', '5', '7', '8', '7', '4', '8', '8', '5', '7', '7', '3', '3', '6', '6', '6', '8', '8', '1', '7', '6', '6', '2', '5', '3', '6', '4', '4', '2', '2', '7', '2', '4', '2', '1', '4']\n"
     ]
    }
   ],
   "source": [
    "from dataset import CLS_Dataset, REG_Dataset, ANO_Dataset\n",
    "from dataset_config import resolve_dataset_config\n",
    "\n",
    "split_ratio = [0.6, 0.2, 0.2]\n",
    "\n",
    "cfg = resolve_dataset_config(research_object)\n",
    "labels = cfg[\"labels\"]\n",
    "random_seed = cfg[\"seed\"]\n",
    "\n",
    "input = list(features.values())[0]\n",
    "input_len = input.shape[0] * input.shape[1]\n",
    "if task_type == 'regression':\n",
    "    input_len = data.shape[1]\n",
    "    total_samples = 100 if input_len > 100 else input_len\n",
    "else:\n",
    "    total_samples = input_len\n",
    "\n",
    "if task_type == 'classification':\n",
    "    dataset = CLS_Dataset(\n",
    "        feature=input,\n",
    "        labels=labels,\n",
    "        total_samples=total_samples,\n",
    "        split_ratio=split_ratio,\n",
    "        random_seed=random_seed\n",
    "    )\n",
    "    dataset.summary()\n",
    "    train_data = dataset.train_data\n",
    "    val_data   = dataset.val_data\n",
    "    test_data  = dataset.test_data\n",
    "    true_labels_val  = dataset.true_labels_val\n",
    "    true_labels_test = dataset.true_labels_test\n",
    "\n",
    "elif task_type == 'regression':\n",
    "    dataset = REG_Dataset(\n",
    "        X=input,\n",
    "        Y=Y,\n",
    "        total_samples=total_samples,\n",
    "        split_ratio=split_ratio,\n",
    "        random_seed=random_seed,\n",
    "    )\n",
    "    dataset.summary()\n",
    "    train_data = dataset.train_data\n",
    "    val_data   = dataset.val_data\n",
    "    test_data  = dataset.test_data\n",
    "    y_val_true  = dataset.y_val_true\n",
    "    y_test_true = dataset.y_test_true\n",
    "\n",
    "elif task_type == 'anomaly detection':\n",
    "    ds = ANO_Dataset(\n",
    "        X=input,\n",
    "        labels=labels,\n",
    "        total_samples=total_samples,\n",
    "        split_ratio=split_ratio,\n",
    "        normal_class=0,\n",
    "        random_seed=random_seed,\n",
    "    )\n",
    "    ds.summary()\n",
    "    train_data = ds.train_data\n",
    "    val_data   = ds.val_data\n",
    "    test_data  = ds.test_data\n",
    "    y_val      = ds.y_val\n",
    "    y_test     = ds.y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62effc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initial test set evaluation ===\n",
      "Prompt tokens: 11031, Completion tokens: 98\n",
      "raw_model_output: [5,5,3,2,1,1,3,5,8,1,4,1,3,5,7,8,7,4,8,8,5,7,7,3,3,6,6,6,8,8,1,7,6,6,2,5,3,6,4,4,2,2,7,2,4,2,1,4]\n",
      "parsed_preds: ['5', '5', '3', '2', '1', '1', '3', '5', '8', '1', '4', '1', '3', '5', '7', '8', '7', '4', '8', '8', '5', '7', '7', '3', '3', '6', '6', '6', '8', '8', '1', '7', '6', '6', '2', '5', '3', '6', '4', '4', '2', '2', '7', '2', '4', '2', '1', '4']\n",
      "true_labels_test: ['5', '5', '3', '2', '1', '1', '3', '5', '8', '1', '4', '1', '3', '5', '7', '8', '7', '4', '8', '8', '5', '7', '7', '3', '3', '6', '6', '6', '8', '8', '1', '7', '6', '6', '2', '5', '3', '6', '4', '4', '2', '2', '7', '2', '4', '2', '1', '4']\n",
      "wrong indices: []\n",
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "## Single turn generation\n",
    "from Generate_single import SpectrumCLS, SpectrumReg, SpectrumAno\n",
    "\n",
    "if task_type == \"classification\":\n",
    "    agent_cls = SpectrumCLS(\n",
    "        train_data=train_data,\n",
    "        test_data=test_data,\n",
    "        true_labels_test=true_labels_test,\n",
    "        api_key=model_API,\n",
    "        base_url=model_url,\n",
    "        model=\"gpt-5-chat-latest\",\n",
    "        #model = \"qwen-turbo-latest\",\n",
    "    )\n",
    "    agent_cls.run()\n",
    "\n",
    "elif task_type == \"regression\":\n",
    "    agent_reg = SpectrumReg(\n",
    "        dataset= dataset,\n",
    "        api_key=model_API,\n",
    "        base_url=model_url,\n",
    "        model=\"gpt-5-chat-latest\",\n",
    "        #model = \"qwen-plus-latest\",\n",
    "    )\n",
    "    agent_reg.run()\n",
    "\n",
    "elif task_type == 'anomaly detection':\n",
    "    agent_ano = SpectrumAno(\n",
    "        dataset = ds,\n",
    "        api_key=model_API,\n",
    "        base_url=model_url,\n",
    "        model=\"gpt-5-chat-latest\",\n",
    "        #model = \"qwen-plus-latest\",\n",
    "    )\n",
    "    agent_ano.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41cbc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Conda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ML][SVM] best_params={'svc__C': 100, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}, CV_best_acc=0.9515, Test_acc=0.9583\n",
      "[ML][KNN] best_params={'knn__n_neighbors': 11, 'knn__p': 1, 'knn__weights': 'uniform'}, CV_best_acc=0.8892, Test_acc=0.8958\n",
      "[ML][RandomForest] best_params={'max_depth': None, 'min_samples_split': 2, 'n_estimators': 300}, CV_best_acc=0.9793, Test_acc=0.9583\n",
      "[NN-CLS] Early stopped at epoch 20, best val_acc=0.9167\n",
      "[NN-CLS] Early stopped at epoch 26, best val_acc=0.9583\n",
      "SVM: Accuracy = 95.83%\n",
      "KNN: Accuracy = 89.58%\n",
      "RandomForest: Accuracy = 95.83%\n",
      "CNN1D: Accuracy = 93.75%\n",
      "Transformer: Accuracy = 95.83%\n"
     ]
    }
   ],
   "source": [
    "## Other models\n",
    "\n",
    "from other_models import ClassificationModelPipeline,RegressionModelPipeline,AnomalyModelPipeline\n",
    "\n",
    "if task_type =='classification':\n",
    "    cls_pipe = ClassificationModelPipeline(train_data, test_data, val_data=val_data, early_stop_patience=5, cv_folds=5)\n",
    "    cls_results = cls_pipe.train_and_evaluate(nn_epochs=50, batch_size=32)\n",
    "\n",
    "elif task_type =='regression': \n",
    "    reg_pipe = RegressionModelPipeline(train_data, test_data, val_data=val_data, early_stop_patience=5, cv_folds=5)\n",
    "    reg_results = reg_pipe.train_and_evaluate(nn_epochs=50, batch_size=32)\n",
    "    \n",
    "elif task_type == 'anomaly detection':\n",
    "    ano_pipe = AnomalyModelPipeline(train_data, test_data, val_data=val_data, early_stop_patience=5, cv_folds=5)\n",
    "    ano_results = ano_pipe.train_and_evaluate(epochs_ae=50, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
